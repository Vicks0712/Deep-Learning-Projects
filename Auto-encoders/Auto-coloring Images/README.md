# Autoencoder for Grayscale Image Colorization

Autoencoders are a type of neural network trained to reconstruct their input. They consist of an "encoder" and a "decoder," where the "encoder" maps the input to a lower-dimensional representation (also known as the **latent vector**), and the "decoder" maps the latent representation back to the original input space.

In this project, we address the task of colorizing black and white (grayscale) images using a convolutional autoencoder. This variant of autoencoder is particularly suitable for image processing. The "encoder" learns to extract features from grayscale images, while the "decoder" maps these features to the corresponding colors.

## Dataset
The dataset chosen for the task consists of a set of images of the characters from the animated series "The Simpsons". To access and download the data, access the following link: https://www.kaggle.com/datasets/victoriatorres/the-simpsons-autocoloring-dataset/data

To work comfortably with our dataset, we have created a DataLoader, an object used in the PyTorch library to efficiently load and process datasets during machine learning model training. We have performed the following transformations on the images:

- Converted the images to RGB format.
- Resized them to a dimension of 64 x 64.
- Changed the image format to YCrCb color space.
- Separated into luminance (Y), chroma red (Cr), and chroma blue (Cb).
- Normalized all 3 channels by dividing them by 255 to scale the values between 0 and 1.

## Model

The model consists of two parts:

### Encoder

The encoder is implicit in the model and comprises 3 convolutional layers. It takes the Y channel (luminance) with a dimension of 1 x 64 x 64 and returns a result with a dimension of 32 x 16 x 16 and a batch size of 64.

### Decoder

The decoder is also implicit in the model and consists of 4 deconvolutional layers. Two layers affect the entire Y channel, and the other two provide the Cr and Cb channels separately. The final result is the two Cr and Cb channels with a size of 1 x 64 x 64.

```
python
class Autoencoder_COLOR(nn.Module):
    def __init(self):
        super().__init()
        # Definition of convolutional and deconvolutional layers
        # ...
    def forward(self, x):
        # Model implementation
        # ...
```
# Used Libraries

This project utilizes several Python libraries for its operation. Below, we outline the primary libraries employed:

- [PyTorch](https://pytorch.org/): A widely used deep learning framework that simplifies the creation and training of machine learning models.
- [NumPy](https://numpy.org/): A fundamental library for array manipulation and numerical computations in Python.
- [Matplotlib](https://matplotlib.org/): A plotting library used to visualize data and results.
- [OpenCV](https://opencv.org/): A computer vision library employed for image manipulation and processing.

Make sure you have these libraries installed in your environment before running the project code.

# Results

We have successfully reconstructed color images from grayscale images using our model. The reconstruction process involves the following steps:

1. Obtaining the Cr and Cb channels from the model.
2. Reorganizing the data into a suitable format for displaying the images.
3. Converting the images to the RGB color space.

Below, we provide visual comparisons between the original images and the resulting images generated by the model for five examples from our dataset:

![image](https://github.com/Vicks0712/Deep-Learning-Projects/assets/90756558/93e40088-45e7-4f15-a705-3c0bedcf9f3b)
![image](https://github.com/Vicks0712/Deep-Learning-Projects/assets/90756558/e912055f-72c3-4555-8e4a-2f08e0f4c05a)


# Usage Instructions

To utilize this code and the autoencoder model for grayscale image colorization, please follow these steps:

1. Clone this repository to your local machine.
2. Ensure that you have all the necessary dependencies installed.
3. Execute the code to either train the model or use it for image reconstruction.
4. Experiment with your own grayscale images.

# Contributions

Contributions to this project are highly encouraged and welcomed. If you wish to enhance the code, rectify errors, or introduce new features, please do not hesitate to submit a pull request.
